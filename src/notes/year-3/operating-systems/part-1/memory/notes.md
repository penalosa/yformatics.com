## Introduction

One goal of memory management is to allocate resources among processes and the operating system. It provides a convenient abstraction for programmers by simplifying memory utilization and addressability. It also provides isolation between processes and the OS.

Programs must be brought from disk into memory and placed within a process context to be run. Main memory and CPU registers are the only storage locations that the CPU can access directly. Programs cannot be run from disk.

The memory unit only sees either the physical memory address and a read request, or the physical memory address and a write request with some data. Cache site between main memory and CPU registers to reduce the number of CPU cycles required to access memory.

## No memory abstraction

Some older operating systems did not abstract memory as modern ones do. This is fairly simple to understand and looks a lot like the way memory was described in the processes section.

With multiple programs running, every program sees physical memory. This means that they can access each other's memory which can lead to security risks and potential overwriting. The total number of programs that can be run depends on the program size and the total amount of physical memory available.

## Binding

Memory addresses in a program are usually symbolic, such as named variable. Binding is the mapping of a symbolic address to another type of address. Multiple parts go into this:

- Compiler (from source to object file)  
  Binds symbolic addresses to relocatable addresses

- Linker (from object file to executable file)  
  Binds relocatable addresses to absolute addresses at compile-time, after the final memory location is decided it cannot be moved without hardware support

- Loader (executable file moved to memory)  
  Binds executable files to absolute addresses when an application is loaded, after the final memory location is decided it cannot be moved without hardware support

## Relocation problem

When multiple programs are loaded into memory, there may be issues where they end up inadvertently pointing to each other as they are unaware of their physical relation to each other. Programs must be relocatable, meaning they are written to be placed and run at any memory address. The loader decides where to place them based on available physical memory.

When the loader relocates a program, it edits all commands in the program relevant to memory so that they are all pointing where they should be within their own program.

## Physical memory

All physical memory is exposed to the processes, meaning that user processes may interfere with the OS and each other. To protect each process, the start and end of each allocated memory slot is loaded into 'base' and 'limit' registers. The CPU checks every memory access generated by each process and if an address is not valid then it traps to the OS.

## Address space

This is an abstraction of physical memory which is a set of addresses that processes can use independently from other processes. This allows each process to act like they are the only one using the memory.

To make it easier to manage memory of multiple processes, make processes use 'logical addresses' that are independent of physical addresses. The OS still manages data in physical memory but instructions issued by the CPU use logical addresses. They are translated by hardware into physical addresses.

Think of each program as having a contiguous logical address space starting at 0 and going up to its size. Each also has a physical address space that starts somewhere in memory.

## Memory-management unit

The memory-management unit (MMU) is the chip that translates logical addresses into physical addresses. The simplest way to implement it is to have a relocation register that can sum addresses. Another implementation uses a relocation register and limit register which catches logical addresses outside the range for that process.

## Contiguous allocation

Main memory must support both the OS and user processes, but it has limited resources so it must allocate them efficiently. Contiguous allocation is an early method that partitions memory into two sections. OS processes are held in lower memory while user processes are held in higher memory.

Relocation and limit registers are used to protect processes from each other. The relocation register contains the smallest physical address that can be accessed and the limit register contains the range of logical addresses that can be accessed by a particular program.

## Multiple partitions

When there are multiple applications in memory, we need to partition memory in several places. These partitions need to have variable sizes for efficiency. The degree of multiprogramming is limited by the number of partitions. When a process arrived, the OS assigns a 'hole' large enough to accommodate it. When a process exits, the partition is returned to the OS and adjacent free partitions are combined.

## Dynamic storage

It can be a challenge for the OS to satisfy incoming memory allocation requests from the list of free holes. There are multiple algorithmic approaches:

- First fit  
  Allocate the first hole that is big enough

- Best fit  
  Allocate the smallest hole that is big enough, requiring the whole list to be searched or ordered by size

- Worst fit  
  Allocate the largest hole, requiring the whole list to be searched or ordered by size

## Swapping

A computer may run hundreds of programs simultaneously, more than can fit in memory at once. To solve this, programs can be swapped from memory to disk while the program is running.

## Growing programs

For most programs, the amount of memory used dynamically grows and shrinks during execution. There are two different allocation methods to support this:

- Allocate growing space for a program at the end, if more space is needed then relocate.

- Allocate growing space for a program inside it, defining maximum growth.

## Fragmentation

Another alternative to the growing problem is fragmentation. This means that when a new process is being allocated, the OS can move all processes tightly together by memory copy or swapping out and in. This is computationally expensive.
